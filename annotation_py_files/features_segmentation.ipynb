{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re, os, sys\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in dynamic features file as 260-dimension dataframe\n",
    "\n",
    "path = '/Volumes/Seagate Expansion Drive/PMEmo dataset/PMEmo/PMEmo/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_features = pd.read_csv(path+'dynamic_features.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arousal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in arousal annotation changepoint locations\n",
    "\n",
    "path = \"/Users/jay/Documents/Jay's bits/Uni/Thesis/thesis-pipeline/data/interim/\"\n",
    "\n",
    "A_bkps = pd.read_pickle(path+'Arousal_breaks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gen_ids(bkps):\n",
    "    \"\"\"generate list of filenames from successfully segmented File_IDs\"\"\"\n",
    "\n",
    "    filenames = []\n",
    "\n",
    "    for fid in bkps['File_ID']:   \n",
    "        y=\"\"\n",
    "        x = list(fid)\n",
    "        x=x[:-6]\n",
    "        for i in x:\n",
    "            y+=i\n",
    "        filenames.append(y)\n",
    "        \n",
    "    return filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate arousal filenames\n",
    "\n",
    "filenames = gen_ids(A_bkps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def segment_features(bkps, features, filenames, dim):\n",
    "    \"\"\"use breakpoints as indexes to segment feature file, generate a list of Series entries\"\"\"\n",
    "    \n",
    "    split_features = []\n",
    "    \n",
    "    if dim=='A':\n",
    "        ext='-A.csv'\n",
    "    else:\n",
    "        ext='-V.csv'\n",
    "    \n",
    "    for fid in filenames:\n",
    "        data = features[features['musicId']==int(fid)].iloc[30:,:]\n",
    "        break_id = str(fid)+ext\n",
    "        breaks = bkps[bkps['File_ID']==break_id]\n",
    "        \n",
    "        if not breaks.empty:\n",
    "            \n",
    "            idxs = bkps[bkps['File_ID']==break_id]['bkps'].iloc[0]\n",
    "        \n",
    "            if len(idxs)==1:\n",
    "\n",
    "                # split_features.append(pd.concat(str(fid), data.mean(axis=0).values))\n",
    "                entry = [str(fid), data.mean(axis=0)]\n",
    "#                entry = [str(fid), data.mean(axis=0).values]\n",
    "\n",
    "                split_features.append(entry)\n",
    "\n",
    "            else:\n",
    "                idxs = idxs[:-1]\n",
    "                feature_splits = np.split(data, idxs)\n",
    "                suffix=1\n",
    "\n",
    "                for i in feature_splits:\n",
    "#                    entry = [str(suffix)+'_'+str(fid), feature_splits[i].mean(axis=0).values]\n",
    "                    entry = [str(suffix)+'_'+str(fid), i.mean(axis=0)]\n",
    "                    split_features.append(entry)\n",
    "                    suffix+=1\n",
    "                    \n",
    "    return split_features\n",
    "                    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_segment_features = segment_features(A_bkps, dynamic_features, filenames, 'A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coerce segmented features into a dataframe\n",
    "\n",
    "ft=[]\n",
    "for i in A_segment_features:\n",
    "    ft.append(i[1])\n",
    "\n",
    "z=[]\n",
    "for i in A_segment_features:\n",
    "    z.append(i[0])\n",
    "\n",
    "z = pd.Series(z, name='File_ID')\n",
    "\n",
    "\n",
    "A_mu_dyn_features = pd.DataFrame(ft)\n",
    "\n",
    "\n",
    "A_mu_dyn_features.insert(0, 'File_ID', z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save segmented arousal features as csv\n",
    "\n",
    "path = \"/Users/jay/Documents/Jay's bits/Uni/Thesis/thesis-pipeline/data/processed/Features/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_mu_dyn_features.to_csv(path+'Arousal_averaged_features.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/jay/Documents/Jay's bits/Uni/Thesis/thesis-pipeline/data/interim/\"\n",
    "\n",
    "V_bkps = pd.read_pickle(path+'Valence_breaks')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = gen_ids(V_bkps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segment audio features based on valence annotation changepoints\n",
    "\n",
    "V_segment_features = segment_features(V_bkps, dynamic_features, filenames, 'V')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft=[]\n",
    "for i in V_segment_features:\n",
    "    ft.append(i[1])\n",
    "    \n",
    "\n",
    "z=[]\n",
    "for i in V_segment_features:\n",
    "    z.append(i[0])\n",
    "    \n",
    "\n",
    "z = pd.Series(z, name='File_ID')\n",
    "\n",
    "\n",
    "V_mu_dyn_features = pd.DataFrame(ft)\n",
    "\n",
    "\n",
    "V_mu_dyn_features.insert(0, 'File_ID', z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/jay/Documents/Jay's bits/Uni/Thesis/thesis-pipeline/data/processed/Features/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_mu_dyn_features.to_csv(path+'Valence_averaged_features.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
